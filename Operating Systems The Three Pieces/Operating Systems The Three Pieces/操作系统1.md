# 操作系统

[TOC]

## 第一次课（概要）

> Operating System: A body of software, in fact, that is responsible for *making it easy to run programs* (even allowing you to seemingly run many at the same time), allowing programs to share memory, enabling programs to interact with devices, and other fun stuff like that. (OSTEP)



操作系统在广义上定义为：管理软/硬件资源，为其他程序提供服务。从这个角度来说，浏览器、固件、微信小程序也是操作系统 。但我们从这里讨论狭义的操作系统。



想要了解操作系统是什么，必须要了解它的发展历史！多任务管理的需求促使操作系统概念的形成。它同时也提供了一些API。为了在程序执行IO操作时提高CPU利用率，操作系统开始支持同时将多个程序载入内存，并引入进程的概念，以及多任务调度机制（基于中断机制），虚拟存储（保护机制）机制。现在，操作系统通过虚拟化硬件资源（非对称多处理器、NUMA、P/E-cores、SSD、网卡、IoT）为软件提供更多、更好的服务。



**应用视角：操作系统 = 对象（socket、驱动、消息队列） + API**（操控对象）

**硬件视角：操作系统 = C程序 + 汇编**



 

## 第二次课（程序与编译器）

以状态机为线索贯穿教学主线。



数字逻辑电路的状态机

- 状态 = 寄存器
- 初始状态 = RESET
- 状态转移 = 组合逻辑电路 + 时序逻辑电路



程序是构建在数字系统上的，因此程序也可以认为是状态机。

**而软件可以利用状态机来模拟硬件系统**！这是一个十分有趣的事情🤣



C语言在语言层面上（源代码）状态机如下

- 状态 = 数据（堆 + 栈）

- 初始状态 = main函数

- 状态转移 = 执行一条语句



进一步，我们考虑到栈帧，修改该模型：

- 状态 = stack frame + 全局变量 + 堆区
- 初始状态 = main(argc, argv)，全局变量初始化
- 状态转移 = PC++（每一个栈帧都有一个PC） / 函数调用与返回



为了加深理解 请看非递归版本的Hanoi

~~~c
typedef struct {
  int pc, n;
  char from, to, via;
} Frame;

#define call(...) ({ *(++top) = (Frame) { .pc = 0, __VA_ARGS__ }; })
#define ret()     ({ top--; })
#define goto(loc) ({ f->pc = (loc) - 1; })

void hanoi(int n, char from, char to, char via) {
  Frame stk[64], *top = stk - 1;
  call(n, from, to, via);
  for (Frame *f; (f = top) >= stk; f->pc++) {
    switch (f->pc) {
      case 0: if (f->n == 1) { printf("%c -> %c\n", f->from, f->to); goto(4); } break;
      case 1: call(f->n - 1, f->from, f->via, f->to);   break;
      case 2: call(       1, f->from, f->to,  f->via);  break;
      case 3: call(f->n - 1, f->via,  f->to,  f->from); break;
      case 4: ret();                                    break;
      default: assert(0);
    }
  }
}

~~~

<img src="C:\Users\Administrator\Desktop\Operating Systems The Three Pieces\picture\1666787463493-screenshot.png" alt="1666787463493-screenshot" style="zoom:50%;" />

<img src="C:\Users\Administrator\Desktop\Operating Systems The Three Pieces\picture\1666787481119-screenshot.png" alt="1666787481119-screenshot" style="zoom:50%;" />

对于一个确定的输入，它的执行流是确定的，因而条件语句所要执行的分支也是一定的。



 二进制代码视角的程序（汇编）

状态 = 内存 + 寄存器

初始状态 = ?

状态转移 = 执行一条机器指令



机器指令指令分为两种：**计算指令**、**Syscall指令**。如果一个程序只有计算指令，那么该程序对应的状态机要么无限制地运行下去，要么**undefined behavior**。当程序执行syscall指令时，它就把自身所有的状态（内存 + 寄存器）提交给操作系统，任其修改，从而实现与操作系统中的其他对象交互。

所以，从应用层的视角来说，**程序 = 计算指令 + syscall指令**。也就是说应用程序只能完成计算工作，其他工作需要操作系统代替它完成。

构造一个“最小”的HelloWorld程序

~~~c
#include <sys/syscall.h>

.globl _start
_start:
  movq $SYS_write, %rax   # write(
  movq $1,         %rdi   #   fd=1,
  movq $st,        %rsi   #   buf=st,
  movq $(ed - st), %rdx   #   count=ed-st
  syscall                 # );

  movq $SYS_exit,  %rax   # exit(
  movq $1,         %rdi   #   status=1
  syscall                 # );

st:
  .ascii "\033[01;31mHello, OS World\033[0m\n"
ed:
~~~

查阅手册：man syscall。

retq指令执行：

~~~asm
rip <- M[rsp]
rsp <- rsp + 8
~~~



以上讨论了两种状态机：源代码状态机、二进制状态机。编译器就是将源代码状态机翻译到二进制状态机，即$C = compile(S)$

正确地编译（优化）意味着：

- 不可优化的部分要严格翻译，这也就是意味着禁止编译器对这一部分进行优化。不可优化部分包括asm volatile、volatile variable等
- 源代码状态机与二进制状态机的可观测行为严格一致。在保证观测一致性 (sound) 的前提下可以改写代码 (rewriting)。



程序的第一条指令是ld-linux-x86-64.so，即加载器libc。加载器的位置是由ELF文件格式规定的，可以hack改变位置！此外，可以在main函数之前，之后执行一些代码

~~~c
#include <stdio.h>

__attribute__((constructor)) void hello() {
  printf("Hello, World\n");
}

// See also: atexit(3)
__attribute__((destructor)) void goodbye() {
  printf("Goodbye, Cruel OS World!\n");
}

int main() {
    
}

~~~



**状态机模型是一个严格的数学对象，也就是有着的形式语义！** **所以，计算机系统不存在玄学；一切都建立在确定的机制上**。

**程序 -> 模型 -> 形式语义（数学定义）-> 验证**



gdb：layout src

gdb：layout asm

gdb：s 下一条指令 

gdb: info frame，打印栈帧

gdb：watch point

gdb：starti 一定是程序的第一条语句，不是main函数的第一条语句。

gdb : start main函数的第一条语句。

gdb : until 执行完循环

gdb ：finish 执行完当前的函数

gdb ： p 打印变量

C语言中的宏，##表示字符串拼接

gcc  --verbose

gcc -static 静态编译

gcc -E 预处理

gcc -S 编译汇编

strace，跟踪所有的系统调用。





## 第三次课（线程）



> Concurrent: existing, happening, or done *at the same time*.
>
> In computer science, concurrency refers to the ability of different parts or units of a program, algorithm, or problem to be executed out-of-order or in partial order, without affecting the final outcome. (Wikipedia)
>
> 系统调用是最早的并发程序！



线程作为并发的基本单位，它是共享内存的多个执行流：

- 执行流拥有独立的栈/寄存器（私有状态），其中栈可以被其他线程通过指针访问到
- 共享进程的全部内存。

**线程之间最原始的通信手段就是共享内存**，但是最好将共享内存封装成API来使用。

> 这种并发状态机模型是很粗糙的，甚至都不对。但是可以方便我们理解并发到底是什么。

显然我们可以将单线程下的状态机模型扩展到并发的状态机模型：

- 状态：全局 + 堆区 + 多个栈帧链（多个线程）。全局以及堆区是由所有线程共享的状态。
- 初始状态：？
- 状态转移：状态转移的方向是不确定的，它的方向是由线程调度决定。而在单线程下，状态转移的方向是确定的，除了Systemcall（I/O）以及随机性质指令（随机数指令）。

![1666787828434-screenshot](C:\Users\Administrator\Desktop\Operating Systems The Three Pieces\picture\1666787828434-screenshot.png)



多线程的工作模型：

- 单处理器多线程：线程在运行时可能被中断，切换到另一个线程执行，这有系统开销

- 多处理器多线程：真正意义上的并行，在多个CPU之间的线程并没有切换的系统开销。它的状态机可以等价单处理器多线程的。



多线程的正确性所面临的三个问题：**原子性，顺序性，可见性！**。**并发程序的性能不受这三个性质的影响。**

![1666787833822-screenshot](C:\Users\Administrator\Desktop\Operating Systems The Three Pieces\picture\1666787833822-screenshot.png)

### 原子性

我们先来看原子性，所谓的**原子性（atomic）**，是指一系列的动作要么都完成，要么都未进行，没有任何**可以被等同外界观察到的**中间状态，整体具有不可分割性。在数据库以及分布式领域中，常常把原子性称为**事务（transaction）**。



而锁实现了临界区之间的绝对串行化，而程序的其他部分仍然可以并行执行。保证了原子性。此外，绝对多数的并发问题都可以用一个任务队列解决（OSTEP 34Chapter）

注意，系统库函数中有些是线程完全的，就比如printf。



**一条汇编指令甚至都不能保证原子性！！** 例如

~~~c
long sum = 0;
void Tsum() {
	for (int i = 0; i < 100000; i++) asm volatile("add $1, %0" : "+m"(sum));
}
int main() {
	create(Tsum); create(Tsum); join();
	printf("sum = %ld\n", sum);
}
~~~

可以通过添加lock指令前缀来保证单条汇编指令的原子性，但是会严重损耗性能。

### 顺序性

~~~c
long sum = 0;
void Tsum() { for (int i = 0; i < 100000000; i++) sum++; }
int main() {
    create(Tsum); create(Tsum); join();
  	printf("sum = %ld\n", sum);
}
~~~

添加编译优化

- `-O1`: 100000000 😱😱，因为 `R[eax] = sum; R[eax] += N; sum = R[eax]`
- `-O2`: 200000000 😱😱😱，因为 `sum += N;`



另一个例子：

~~~c
while (!done);
// would be optimized to
if (!done) while (1);
~~~

这是因为编译器是在单线程模型下进行优化的。而且编译器对内存访问进行 “eventually consistent” 处理。

要解决这一问题，要插入**compile barrier**，阻止编译器优化，例如：

- asm volatile ("" ::: "memory");
- volatile变量
- __sync_synchronize()提供内存屏障，而且阻止编译器进行优化。

### 可见性（了解即可）

这个程序说明了可见性对多线程的影响：http://jyywiki.cn/pages/OS/2022/demos/mem-ordering.c。按状态机分析，输出只可能有01、10、11，但它的输出里居然有00.



现代处理器是动态数据流分析器，也就是将一条汇编指令**编译并优化**成多条微指令的动态编译器。每个微指令都有Fetch、Issus、Execute、Commit四个阶段，可以看作一个状态机。在同一个周期中，会Issus多条指令，它们会乱序执行（注意数据依赖的影响），并且按序提交。

注意：

~~~asm
movl $1, (x)
movl (y), %eax
~~~

如果x发生了cache miss，那么读y可能在写x之前发生。



x86是“最强”的内存模型：历史包袱重

![img](http://jyywiki.cn/pages/OS/img/x86-tso.png)

这里有写缓冲队列，使得写操作是有延迟的。



RISC-V采用宽松的内存模型：![img](https://research.swtch.com/mem-weak@2x.png)



可以使用mfence指令解决可见性问题。它保证在写入到共享内存后再执行下一条指令。

~~~asm
movl $1, (x)
mfence
movl (y), %eax
~~~



### 小知识

~~~c

__thread char *cur; // thread-local variables
__attribute__((noinline)) char *get_cur()         { return cur; }	//拒绝编译器的内联优化
~~~

wget https://.... 下载文件

top查看系统资源的利用情况

gcc -c 只会编译，不会链接生成可执行文件。

vim在命令模式下直接输入ngg或者nG，光标就移动到第n行。

输入: n,md删除第n行到第m行。

有时候习惯性输入 ctrl + S，此时vim无响应，仅需输入ctrl + q即可恢复执行。

objdump 反汇编命令。`objdump -d <file(s)>`: 将代码段反汇编；`objdump -S <file(s)>`: 将代码段反汇编的同时，将反汇编代码与源代码交替显示，编译时需要使用`-g`参数，即需要调试信息；

| 创建管道，前面的输出就是后面的输入。> 重定向，将命令的输出重定向到后面的程序，<是将命令的输入重定向到后面的程序

& 后台执行， && 依次执行命令，直到执行完成或者命令出错。|| 执行到某条命令成功



### 内联汇编

~~~c
asm ( assembler template
        : output operands                /* optional */
        : input operands                   /* optional */
        : list of clobbered registers   /* optional */
);
~~~

举个例子

~~~c
int a = 10, b;
asm volatile (
    "movl %eax, %ebx;"
    "add $1, %ebx;"
    : "=r"(b)
    : "r"(a)
    : "%ecx", "%edi"
   )
~~~



list of clobbered registers会通知编译器可能会破坏寄存器/内存里面的数据，然后编译器就会将这些可能被破坏的内存和寄存器提前保护起来。

一般的，如果在 Output 和 Input 部分指定了寄存器约束，那么编译器一定知道该寄存器被改变了，那么就不用申明。

**寄存器约束就是要求编译器使用哪个寄存器，将 Output 和 Input 的变量约束到哪个寄存器**

a: eax/ax/al；

b: ebx/bx/bl；

c: ecx/cx/cl；

d: edx/dx/dl

D: edi/di；

S: esi/si

r: eax/ebx/ecx/edx/esi/edi 之一；

q: eax/ebx/ecx/edx 之一

f: 浮点寄存器

t: 第一个浮点寄存器

u: 第二个浮点寄存器

注意：编译器会**额外生成一些汇编代码**将寄存器中的结果赋给变量，或者将变量加载到指定寄存器中。这些工作在执行指令模板前后完成。



**内存约束是将变量的地址作为汇编代码的操作数，不需要寄存器作为中转，直接进行内存读写**。这需要占位符的配合，以一个例子来说明：

~~~c
asm("movl %0, %1"::"a"(in_a),"m"(in_b));
~~~

%0对应in_a的寄存器，而%1对应in_b的地址。

**”0，1，2，3，4，5，6，7，8，9“，也只用在 Input 部分，表示与 Output 和 Input 中第 n 个变量使用相同的寄存器或内存**。



修饰符的使用

- =：表示操作数是只写的，一般存在 Output 中。
- +：表示操作数是可读可写的，相应的寄存器或内存先被读再被写入。
- &：表示该操作数要独占相应的寄存器。

更多知识请见https://zhuanlan.zhihu.com/p/395130640

## 第四次课（Peterson算法、模型检验、软件自动化工具）



> 可以做这样一个假设：对同一个内存读写是不可能同时发生的。



互斥 (mutual exclusion)，即“互相排斥”。互斥实现了**临界区之间**的**绝对串行化**，从而保证了原子性。

我们用锁来实现互斥：`lock_t` 数据结构和 `lock/unlock` API:

~~~c
typedef struct {
  ...
} lock_t;
void lock(lock_t *lk);
void unlock(lock_t *lk);
~~~

如果线程A持有锁对象，而此时线程B想要通过lock()获取到该锁，那么它会被阻塞直到线程A释放该锁。

实现锁的关键是实现该事务——同时读/写内存，以原子性地改变锁的状态。该事务可以认为是**次小的事务**。**最小的事务**是原子性的写操作等原子指令。



Peterson算法，在软件层面上实现了一种互斥协议。Dekker算法也是正确的，但更复杂。Peterson就是Dekker算法的简化版本。

### 正确性

在不考虑可见性以及顺序性前提下，证明Peterson算法正确性：

- **穷举法**，最好枚举状态机的所有状态



![1666787839731-screenshot](C:\Users\Administrator\Desktop\Operating Systems The Three Pieces\picture\1666787839731-screenshot.png)

### 自动证明：模型检验

因为我们有程序的形式语义（数学描述），那么我们可以使用自动化证明技术对并发正确性进行验证。

Model Checker的例子：

http://jyywiki.cn/pages/OS/2022/demos/model-checker.py

http://jyywiki.cn/pages/OS/2022/demos/visualize.py

测试用例：

http://jyywiki.cn/pages/OS/2022/demos/mutex-bad.py

http://jyywiki.cn/pages/OS/2022/demos/peterson-flag.py

http://jyywiki.cn/pages/OS/2022/demos/dekker.py

~~~shell
$ python3  model-checker.py dekker.py | python3 visualize.py -r > a.html
$ python3  model-checker.py dekker.py | python3 visualize.py -t > a.html
$ x-www-browser a.html
~~~

- 选择好的语言，例如动态解释语言Python！
- 格式化输出，输出视觉化

实现细节：

- 异步迭代语句 yield。类似于Javascript的迭代器。保留函数的状态，相当于创建了一个状态机。这样在线程代码中每一条语句前添加yield，并返回当前线程的状态。
- BSF得到所有可能的状态机执行序列 、状态空间、合并重复状态



只要为系统建立状态机模型，那么系统的正确性问题就会转换为图论问题。

此外Model Checker有一些Paper：

真实程序的状态空间太大？

- [Model checking for programming languages using VeriSoft](https://dl.acm.org/doi/abs/10.1145/263699.263717) (POPL'97, 第一个 “software model checker”)
- [Finding and reproducing Heisenbugs in concurrent programs](https://dl.acm.org/doi/10.5555/1855741.1855760) (OSDI'08, Small Scope Hypothesis 🪳🪳🪳)
- [Using model checking to find serious file system errors](https://dl.acm.org/doi/10.1145/1189256.1189259) (OSDI'04, Best Paper 🏅，可以用在不并发的系统上)

------

不满足于简单的内存模型？

- [VSync: Push-button verification and optimization for synchronization primitives on weak memory models](https://dl.acm.org/doi/abs/10.1145/3445814.3446748) (ASPLOS'21, Distinguished Paper 🏅)



> 操作系统是一个复杂且巨大的工程，所以一定要使用自动化工具帮助我们做验证、调试、编程工作！

## 第五次课（锁）



在软件方面实现互质是困难重重的，因此我们可以借助硬件来实现。

> 当面对棘手的问题时，可以更改问题的条件/假设，来简化问题。



lock指令前缀，确保指令访问内存是原子性的。同时它还保证：

- 保证原子指令之前的 store 都写入内存
- 保证 load/store 不与原子指令乱序。准确点来说，原子指令之前的load/store指令访问内存是不越过原子指令的。
- 在多处理器中，保证同时仅有一个lock指令执行。



486 (20-50MHz) 就支持 dual-socket 了，此时两个CPU之间共享同一块内存。如果执行lock指令，那么它会将内存锁住，阻止另一个CPU访问内存。如果两个CPU同时执行lock指令，那么由总线判优。这使得x86背负沉重的历史包袱，尤其是现代引入了CPU内部缓存，如果要执行lock指令，那么必须维护缓存一致性，这十分损耗性能。

![img](http://jyywiki.cn/pages/OS/img/80486-arch.jpg)



RISC-V原子操作（Load-Reserved/Store-Conditional）的设计得很巧妙。它的基本思想是在本地寄存器中做的计算是不重要的，最重要的是在内存中所共享的状态，如果状态不一致，那么重复本地计算。



LR：在内存上标记 reserved，中断、其他处理器写入都会导致标记消除。多次load，标记仍然有效，因为状态并没有改变。

~~~risc-v
lr.w rd, (rs1)
  rd = M[rs1]
  reserve M[rs1]
~~~

SC：如果标记仍存有，则写

~~~risc-v
sc.w rd, rs2, (rs1)
  if still reserved:
    M[rs1] = rs2
    rd = 0
  else:
    rd = nonzero
~~~

Compare-and-Swap 的 LR/SC 实现

~~~risc-v
cas:
  lr.w  t0, (a0)       # Load original value.
  bne   t0, a1, fail   # Doesn’t match, so fail.
  sc.w  t0, a2, (a0)   # Try to update.
  bnez  t0, cas        # Retry if store-conditional failed.
  li a0, 0             # Set return to success.
  jr ra                # Return.
fail:
  li a0, 1             # Set return to failure.
  jr ra                # Return
~~~

注意RISC-V原子性指令可以检测原子操作的拥堵情况，例如在fail中处理原子性操作失败的情况。

![img](http://jyywiki.cn/pages/OS/img/boom-pipeline-detailed.png)



### 自旋锁

~~~c
//将newval赋值给addr，并返回addr的旧值。
int xchg(volatile int *addr, int newval) {
    int result;
	asm volatile （
        "lock xchg %0, %1"
        : "+m"(*addr), "=a"(result)
        : "1"(newval) ）
     return result;
}

~~~

更多的原子指令：https://en.cppreference.com/w/cpp/header/stdatomic.h

注意：xchg指令本身就是原子性的，可以不带lock指令前缀。xchg实现了读写同时发生（对于外界来说）。



实现互斥：自旋锁

~~~c
int locked = 1;		//1表示锁空闲，0表示锁已经被占用
void lock() {
retry:
	int got = xchg(&locked, 0);  //注意，返回的addr旧值并不一定是传入addr时的值。
    if (got == 0) goto retry;
    assert(got == 1);
}
void unlock() { xchg(&locked, 1); }
~~~



缺陷：

- 自旋锁的实现需要原子指令。而原子指令会使得处理器之间的缓存同步，增加延迟
- 获得锁的线程执行IO操作或者被调度出去，而其他线程只能空转等待。在单核系统中，这种性能损耗会更加严重。

它的使用场景：

- 临界区几乎不拥堵，且临界区较短。
- 持有自旋锁的线程最好禁止被切换出去，也就是说要禁用中断。这一点决定了只有操作系统使用自旋锁，否则用户就有执行调度的权限。





### 互斥锁

并发正确性是一方面，而性能又是一方面。在性能方面，我们用伸缩性（Scalability）刻画，它是指同一份计算任务的时空资源会随着计算资源（CPU、Thread）而变化。对于伸缩性的测量是很困难的，因为要考虑到各种因素，就比如CPU的动态功耗。





互斥锁一般用于长临界区的互斥。互斥锁最关键的一点是不会让线程空转等待，而是休眠。休眠操作就决定了互斥锁只能在操作系统内核实现。而自旋锁可以在用户代码中实现

### Futex 

Futex = 自旋锁 + 互斥锁

自旋锁由一条原子指令实现，它的fast path快，而slow path慢。互斥锁的slow path快（直接休眠），而fast path慢（需要切换到内核态）。

在算法设计中，我们经常要优化最坏情况下的时间复杂度。而在操作系统中，我们要优化平均情况的时间复杂度，这是因为操作系统设计是一个工程问题，要遵循2/8定律才能带来最好的收益。



time命令 测量程序的运行时间（系统 + 用户）。

## 第六次课（并发控制：同步）

### 同步

同步（Synchronization）的抽象定义：两个或两个以上随着时间变化的量，在变化过程中保持一定的相对关系。

异步（Asynchronous）。

在操作系统中同步意味着：在某个时间点共同到达相互已知的状态。也就是说，一个线程先到达这个状态，那么他就要等到另一个线程到达这个状态后才能继续执行。

实现同步可以用：信号量、条件变量。

互斥是同步的特殊情况——在某些线程执行完事务后，其他线程才能执行该事务。互斥主要是用于保证原子性的！



### 生产者-消费者问题

绝大多数的实际并发问题都可以用生产者-消费者来解决。

先给出用锁解决该问题：

~~~c
int n, count = 0;
mutex_t lk = MUTEX_INIT();
void Tproduce() {
  while (1) {
  retry:
    mutex_lock(&lk);
    if (count == n) {			//如果已满，那么就停止等待。
      mutex_unlock(&lk);
      goto retry;
    }
    count++;
    printf("(");
    mutex_unlock(&lk);
}
   
void Tconsume() {
  while (1) {
  retry:
    mutex_lock(&lk);
    if (count == 0) {		//如果已空，那么就停止等待
      mutex_unlock(&lk);
      goto retry;
    }
    count--;
    printf(")");
    mutex_unlock(&lk);
  }
}

int main(int argc, char* argv[]) {
    for (int i = 0; i < 8; i++) {
		create(Tproduce);
         create(Tconsume);
    }
}
~~~

但是这样并发粒度太大。即使这里的锁是互斥锁，只要没有其他消费者获取该锁，那么生产者在临界条件满足时会一直重复获取该锁，这就相当于自旋锁了。这使得CPU利用率严重下降。为此引入条件变量，它使得生产者在临界条件满足时，不会一直尝试获取该锁，而是休眠直到消费者给它发送信号而唤醒它，从而提高CPU的利用率。



再给出用同步变量解决该问题。先给出一个错误的实现：

~~~c
#include "thread.h"
#include "thread-sync.h"

int n, count = 0;
mutex_t lk = MUTEX_INIT();
cond_t cv = COND_INIT();

void Tproduce() {
  while (1) {
    mutex_lock(&lk);
    if (count == n) {
      cond_wait(&cv, &lk);
    }
    printf("("); count++;
    cond_signal(&cv);
    mutex_unlock(&lk);
  }
}

void Tconsume() {
  while (1) {
    mutex_lock(&lk);
    if (count == 0) {
      pthread_cond_wait(&cv, &lk);
    }
    printf(")"); count--;
    cond_signal(&cv);
    mutex_unlock(&lk);
  }
}

int main(int argc, char *argv[]) {
  assert(argc == 2);
  n = atoi(argv[1]);
  setbuf(stdout, NULL);
  for (int i = 0; i < 8; i++) {
    create(Tproduce);
    create(Tconsume);
  }
~~~

这里有两个错误，它们分别是：

- if语句更改为while语句，原因见下。
- cond_signal()更改为cond_broadcast()，或者用两个条件变量分别表示已空、已满的状态。

因为cond_signal可以唤醒生产者、也可能唤醒消费者。如果消费者cond_broadcast消费者，并且语句是if，那么消费者可能发现没数据可以处理，就发生异常错误。而消费者cond_signal消费者，而语句是while，那么就会发生死锁。总之while语句和cond_broadcast要搭配使用，而且条件判断时总是使用while语句一定是没有错的。





### 哲学家吃饭

一个失败的尝试：[philosopher.c](http://jyywiki.cn/pages/OS/2022/demos/philosopher.c) 

如果所有人同时得到左手叉子，那么就会形成死锁

一个成功的尝试（万能方法）：

~~~c
mutex_lock(&mutex);
while (!(avail[lhs] && avail[rhs])) {
  wait(&cv, &mutex);
}
avail[lhs] = avail[rhs] = false;
mutex_unlock(&mutex);

mutex_lock(&mutex);
avail[lhs] = avail[rhs] = true;
broadcast(&cv);
mutex_unlock(&mutex);
~~~



分布式系统中常见的解决思路：

~~~c
void Tphilosopher(int id) {
  send_request(id, EAT);
  P(allowed[id]); // waiter 会把叉子递给哲学家
  philosopher_eat();
  send_request(id, DONE);
}

void Twaiter() {
  while (1) {
    (id, status) = receive_request();
    if (status == EAT) { ... }
    if (status == DONE) { ... }
  }
}
~~~

这是集中式的同步（Leader/follower、master/slave）。与之相对的是，自组织式的同步（分布式同步），它们共同遵循一个协议。而集中式的同步有性能瓶颈，但是在实际工程问题中讨论的话，集中式同步就足够了，记住**Premature optimization is the root of all evil**（D. E. Knuth）。而且系统设计的好，集中式同步不会成为性能瓶颈。例如，slave的执行时间远远大于master处理请求的时间。如果一个master搞不定，可以设计为层级式master。



> 不推荐用精巧的、耍小聪明的方法去解决问题，尤其是在几百万代码项目中和数以千计的开发者一起合作的情境下。推荐使用简单、直观、易理解的方法去解决问题。

### 条件变量

~~~c
pthread_cond_init();	//初始化一个条件变量
pthread_cond_wait();	//阻塞并释放持有的锁，直到被唤醒
ptread_cond_signal();	//至少唤醒一个阻塞在该条件变量上的线程
pthread_cond_broadcast();	//唤醒全部阻塞在条件变量上的线程
~~~



计算图：计算结果之间的依赖关系，用有向图表示。对计算图拓扑排序，形成计算层，算完计算层$i$才能算计算层$i + 1$。计算层中各个计算节点可以并行处理。

LCS的计算图：

![1666787823768-screenshot](C:\Users\Administrator\Desktop\Operating Systems The Three Pieces\picture\1666787823768-screenshot.png)

更古怪的面试题：
有三种线程：分别打印<，>，_。对这些线程进行同步，使得打印出的序列总是`<><_`和`><>_`组合。思路：状态机，转移条件就是打印字符。



条件变量实现并行计算：（任务队列）。它每次执行一个任务（串行化），从而将这一个任务视为事务，因此在任务中不需要加锁。Javascript引擎、GUI的消息队列就使用这种模型。

~~~c
struct job {
  void (*run)(void *arg);
  void *arg;
}

while (1) {
  struct job *job;

  mutex_lock(&mutex);
  while (! (job = get_job()) ) {
    wait(&cv, &mutex);
  }
  mutex_unlock(&mutex);

  job->run(job->arg); // 不需要持有锁
                      // 可以生成新的 job
                      // 注意回收分配的资源
}
~~~




### 信号量

在**一单位资源**（资源可量化）明确的问题上，可以使用信号量。信号量有P操作（prolaag）以及V操作（verhoog）。P操作表示获取资源，V操作表示创造资源。单纯的同步问题有条件变量这种更好的选择，而事务实现可以用锁。

注意一定要明确资源状态。比如缓冲队列实际上有两个状态：剩余量、已有量。而常常犯的错误是将缓冲队列整体视为一个状态。

一定要用**压力测试**与**模型检验**检测并发程序的正确性。而且不要基于已知的错误行为来进行测试，而是尽可能的覆盖到所有未知的测试情况。



## 第七次课（高性能计算HPC）

### 高性能计算

> “A technology that harnesses the power of supercomputers or computer clusters to solve complex problems requiring massive computation.” (IBM)

以计算为中心

- 系统模拟：天气预报、能源、分子生物学
- 人工智能：神经网络训练
- 矿厂：纯粹的 hash 计算（去中心化，但是消耗能量巨大）
- [HPC-China 100](http://www.hpc100.cn/top100/20/)



此外并发另一个重要指标就是可分解性，就是将整个计算任务切分成多个独立的小任务。根据计算图分解。

任务分解两层：机器、线程、线程之间的通信。

由于物理世界中的局部性，我们在模拟某个物理系统时，很容易将它切分成一个个子系统。对子系统做并行计算即可，要注意系统的近似处理以及切分所形成的边界情况。对与宏观世界的模拟可以用**有限元模型**。而对于微观世界的可以用**量子模型**。

显然在HPC中，需要**机器-线程两级任务分解**。而且还要处理好线程之间的通信，以下给出两个库用于解决通信问题：

> [MPI](https://hpc-tutorials.llnl.gov/mpi/) - “a specification for the developers and users of message passing libraries”, [OpenMP](https://www.openmp.org/) - “multi-platform shared-memory parallel programming in C/C++ and Fortran”



下面再给出一个小例子MandelbrotSet：http://jyywiki.cn/pages/OS/2022/demos/mandelbrot.c

![img](http://jyywiki.cn/pages/OS/img/Mandelbrot.jpg)



- ppm格式，Linux内置的图片格式

- popen函数，在命令行打印图片

- convert命令 图片转换格式





### 数据中心

![img](http://jyywiki.cn/pages/OS/img/datacenter.jpg)

制冷工程问题是数据中心至关重要的问题。

> “A network of computing and storage resources that enable the delivery of shared applications and data.” (CISCO)



数据中心中的主要挑战是多副本情况下的高可靠、低延迟数据访问。

在服务海量地理分布请求的前提下

- 数据要保持一致 (Consistency)

- 服务时刻保持可用 (Availability)

- 容忍机器离线 (Partition tolerance)



CAP只能同时实现两个

![img](http://jyywiki.cn/pages/OS/img/CAP-theorem.png)



数据中心与并发的关系：数据中心中的计算机接受网络请求来执行相应的操作，所以它要尽可能多地处理请求。关键指标：QPS（每秒处理请求）、tail latency。

![1666788070707-screenshot](C:\Users\Administrator\Desktop\Operating Systems The Three Pieces\picture\1666788070707-screenshot.png)



并发的工具：

- 线程：可以利用多个处理器，而每个线程占用相当的操作系统资源。如果该线程被阻塞，那么操作系统可以调用其他的线程。
- 协程（coroutines）：仅保存寄存器以及栈，无需系统调用，系统开销少。协程不受操作系统调度的，可能阻塞包含多个协程的线程。

Go的Goroutine实际上是线程和协程的混合体。它解决了高并发IO的问题。此外还有Java的虚拟线程。它将IO调用翻译成非阻塞的系统调用。

![1666788305387-screenshot](C:\Users\Administrator\Desktop\Operating Systems The Three Pieces\picture\1666788305387-screenshot.png)

在实际工程中，底层知识是最危险的，只有在Debug以及造轮子时才考虑使用，因为它们的可维护性、抽象性都很差，很容易会出错。就好像你不会用汇编写项目一样:)。在操作系统中也是如此，那些并行协议（Pattern）、条件变量、生产者-消费者在工程中我们不用亲自实现，而是直接使用对应的API。

Go用管道（实际上就是生产者与消费者）解决Gorountine之间通信的问题，它不会使用共享内存的。

> Do not communicate by sharing memory; instead, share memory by communicating. ——*Effective Go*





### 浏览器

> “Users were encouraged to provide content, rather than just viewing it.” Web 2.0

Web2.0背后的技术：

- 浏览器中的并发编程：Ajax（Asynchronous Javascript + XML），动态交互技术。
- DOM Tree + CSS

它的特点就是对计算性能、I/O（甚至没有，出于安全考虑）、网络请求的需求都不高。

所以它采用单线程 + 事件模型。执行的基本单位就是事件，而且事件是原子性的。这种方案适合网页这种 “大部分时间花在渲染和网络请求” 的场景，avaScript 代码只负责 “描述” DOM Tree



这种方案的缺点就是“回调地狱”，导致代码可维护性变差。导致 callback hell 的本质：人类脑袋里想的是 “流程图”，看到的是 “回调”。Promise对象在一定程度上可以缓解这种现象

对于网络请求：

- 它是非阻塞异步的，
- 与客户端代码是并行的
- 由浏览器负责的。



![1666788174436-screenshot](C:\Users\Administrator\Desktop\Operating Systems The Three Pieces\picture\1666788174436-screenshot.png)

并发编程的真实应用场景

- 高性能计算 (注重任务分解): 生产者-消费者 (MPI/OpenMP)
- 数据中心 (注重系统调用): 线程-协程 (Goroutine)
- 人机交互 (注重易用性): 事件-流图 (Promise)





Vscode 实际上就是一个浏览器。





## 第八次课

软件是需求（规约）在计算机世界的投影。

BUG根本原因：编程语言的缺陷——在用编程语言模型表示一个现实的事物时，很大程度上会丢失它的部分属性，而且还要符合计算机体系结构的模型。以前计算资源稀缺，程序员的素质都很高，所以程序十分相信程序员，现在情况有所变化:(。

目前有以下几个研究方向来缓解这种问题：

- Annotation verifier ([Dafny](https://dafny-lang.github.io/dafny/))
- Specification mining ([Daikon](http://plse.cs.washington.edu/daikon/))
- [Refinement types](https://dl.acm.org/doi/10.1145/113446.113468)
- [Program sketching](https://link.springer.com/article/10.1007/s10009-012-0249-7)……

BUG产生的另一个原因就是程序所要维护的状态太多了，程序员根本不可能顾及全部，因此会忽略某些条件而导致BUG产生



防御性编程：应对任何BUG

把程序需要满足的条件用assert（if + exception）表达出来。assert检验部分与业务代码部分是相互独立的，而又相互验证的。



### 并发BUG

### 死锁

AA-Deadlock

如果一个线程在持有同一个spinlock后，又再次试图获取这个spinlock，那么将导致死锁的发生。在函数多层嵌套时很有可能发生。解决方法是防御性编程——在将要获取锁时，assert是否获得该锁。



ABBA-Deadlock

解决方案：严格按照固定的顺序获得所有锁Lock Ordering:。应用 (Linux Kernel: rmap.c)：

![img](http://jyywiki.cn/pages/OS/img/kernel-rmap.png)



### 数据竞争

数据竞争用事务来解决。设计锁的根本目的就是来解决数据竞争的



回顾我们实现并发控制的工具

- 互斥锁 (lock/unlock) - 原子性
- 条件变量 (wait/signal) - 同步



- 忘记上锁——原子性违反 (Atomicity Violation, AV)。例子：![img](http://jyywiki.cn/pages/OS/img/tocttou.png)

- 忘记同步——顺序违反 (Order Violation, OV)。



Empirical study: 在 105 个并发 bug 中 (non-deadlock/deadlock)

- MySQL (14/9), Apache (13/4), Mozilla (41/16), OpenOffice (6/2)
- 97% 的非死锁并发 bug 都是 AV 或 OV。





运行时的死锁检查：Lockdep。为每一个锁确定唯一的“allocation site”，例如初始化时所在源代码的行数。然后再动态生成有向图。

- 记录所有观察到的上锁顺序，例如$ [x, y, z] \Rightarrow x \to y, x \to z, y \to z$
- 检查是否存在$ x \rightsquigarrow y \land y \rightsquigarrow x$

[Lockdep 的实现](http://jyywiki.cn/OS/OS_Lockdep)

- Since Linux Kernel 2.6.17, also in [OpenHarmony](https://gitee.com/openharmony)!



运行时的数据竞争检查：ThreadSanitizer。它为所有事件建立 happens-before 关系图

- Program-order + release-acquire
- 对于发生在不同线程且至少有一个是写的 x,y*x*,*y* 检查$x \prec y \lor y \prec x$

![1666788405481-screenshot](C:\Users\Administrator\Desktop\Operating Systems The Three Pieces\picture\1666788405481-screenshot.png)

状态机分析是属于静态程序分析。

动态程序分析：

- 在事件发生时记录
	- Lockdep: lock/unlock
	- ThreadSanitizer: 内存访问 + lock/unlock
- 解析记录，检查问题
	- Lockdep: x \rightsquigarrow y \land y \rightsquigarrow x*x*⇝*y*∧*y*⇝*x*
	- ThreadSanitizer: x \not\prec y \land y \not\prec x*x*\\≺*y*∧*y*\\≺*x*

付出的代价：程序执行变慢



动态分析工具：Sanitizers

- AddressSanitizer非法内存访问
- ThreadSanitize 数据竞争
- [MemorySanitizer](https://clang.llvm.org/docs/MemorySanitizer.html) (msan): 未初始化的读取
- UBSanitizer：undefined behavior

这些工具是由编译器实现的，为了减少内核开发的痛苦😑





这些工具本质上就是一种防御性编程，只不过我们无需在手写代码以及实现复杂的检查机制，从而维护代码的简洁性、可读性。



Buffer Overrun检查

Canary（金丝雀）：牺牲一些内存单元，来预警memory error的发生。操作系统会定期检查金丝雀，如果发现被修改，则报错。

![1666788344851-screenshot](C:\Users\Administrator\Desktop\Operating Systems The Three Pieces\picture\1666788344851-screenshot.png)

Windows中的msvc  debug mode 的 guard/fence/canary（几乎不占用内存）

- 未初始化栈: `0xcccccccc`
- 未初始化堆: `0xcdcdcdcd`
- 对象头尾: `0xfdfdfdfd`
- 已回收内存: `0xdddddddd`

这也是为什么手持“两把锟斤拷，口中疾呼烫烫烫

脚踏千朵屯屯屯，笑看万物锘锘锘”的原因（对应gb2312编码）。





## 工具使用

/r控制字符，可以回到行首，以刷新命令行。
